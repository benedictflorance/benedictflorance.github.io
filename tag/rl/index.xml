<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RL | Benedict Florance Arockiaraj</title>
    <link>https://benedictflorance.github.io/tag/rl/</link>
      <atom:link href="https://benedictflorance.github.io/tag/rl/index.xml" rel="self" type="application/rss+xml" />
    <description>RL</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 15 May 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://benedictflorance.github.io/media/icon_hu9eeb12546e8517e7f9c186d851ae3ad9_1969_512x512_fill_lanczos_center_3.png</url>
      <title>RL</title>
      <link>https://benedictflorance.github.io/tag/rl/</link>
    </image>
    
    <item>
      <title>Unsupervised Reinforcement Learning via World Models</title>
      <link>https://benedictflorance.github.io/project/model_rl/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      <guid>https://benedictflorance.github.io/project/model_rl/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Designing a model-based reinforcement-learning approach via world models using a novel combination of intrinsic and sparse extrinsic reward for robotic manipulation tasks in MetaWorld and adapting to new tasks exploiting prior experience.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Advisors:&lt;/strong&gt; &lt;a href=&#34;https://www.cis.upenn.edu/~kostas/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kostas Daniilidis&lt;/a&gt; and &lt;a href=&#34;https://www.seas.upenn.edu/~oleh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Oleg Rybkin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Transfer Learning for Car-Racing Environments</title>
      <link>https://benedictflorance.github.io/project/transfer_rl/</link>
      <pubDate>Sun, 24 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://benedictflorance.github.io/project/transfer_rl/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Used transfer learning to achieve the fast lap times in OpenAIâ€™s Car racing environment by training the agent on one circuit, and racing it on other
customized target environments by zero-shot transfer or by additional fine-tuning.&lt;/li&gt;
&lt;li&gt;Compared the performance of
model-based and model-free approaches, and observed that model-based approaches dominate in performance and converge
faster than model-free approaches in this environment.&lt;/li&gt;
&lt;li&gt;Observed that transfer learning in most setups not only boosts the
performance on the target domain, but also shows high performance ability during learning.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
